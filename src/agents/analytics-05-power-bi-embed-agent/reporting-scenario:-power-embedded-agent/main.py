#!/usr/bin/env python3
"""
reporting-scenario:-power-embedded-agent - Autonomous Goal-Seeking Agent

Generated by Amplihack Goal Agent Generator
"""

import sys
from pathlib import Path

# Add parent directory to path for amplihack imports
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from amplihack.launcher.auto_mode import AutoMode
except ImportError:
    print("Error: amplihack package not found")
    print("Install with: pip install amplihack")
    sys.exit(1)


def main():
    """Execute the goal-seeking agent."""
    # Load configuration
    config = {
        "max_turns": 18,
        "initial_prompt": '# Goal: Scenario: Power BI Embedded Reports\n\n## Objective\n# Scenario: Power BI Embedded Reports\n\n## Technology Area\nAnalytics\n\n## Company Profile\n- **Company Size**: Mid-size SaaS company\n- **Industry**: Technology / Business Intelligence\n- **Use Case**: Embed Power BI reports into customer-facing applications\n\n## Scenario Description\nDeploy Power BI Embedded capacity with datasets and reports. Create service principal for programmatic access, configure capacity scaling, and demonstrate report embedding in applications.\n\n## Azure Services Used\n- Power BI Embedded (capacity)\n- Power BI API\n- Azure Service Principal (authentication)\n- Azure Key Vault (credentials storage)\n\n## Prerequisites\n- Azure subscription with Contributor role\n- Azure CLI installed\n- A unique identifier for this scenario run\n\n---\n\n## Phase 1: Deployment and Validation\n\n### Environment Setup\n```bash\n# Set variables\nUNIQUE_ID=$(date +%Y%m%d%H%M%S)\nRESOURCE_GROUP="azurehaymaker-analytics-powerbi-${UNIQUE_ID}-rg"\nLOCATION="eastus"\nPOWERBI_CAPACITY="azurehaymaker-pbi-${UNIQUE_ID}"\nKEYVAULT="azurehaymaker-kv-${UNIQUE_ID}"\nAPP_NAME="azurehaymaker-powerbi-app-${UNIQUE_ID}"\n\n# Tags\nTAGS="AzureHayMaker-managed=true Scenario=analytics-power-bi-embed Owner=AzureHayMaker"\n```\n\n### Deployment Steps\n```bash\n# Step 1: Create Resource Group\naz group create \\\n  --name "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 2: Create Key Vault for storing credentials\naz keyvault create \\\n  --name "${KEYVAULT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 3: Create Service Principal for Power BI access\nSP_OUTPUT=$(az ad sp create-for-rbac \\\n  --name "${APP_NAME}" \\\n  --role Reader)\n\nSP_OBJECT_ID=$(echo ${SP_OUTPUT} | jq -r \'.id\')\nSP_CLIENT_ID=$(echo ${SP_OUTPUT} | jq -r \'.appId\')\nSP_TENANT_ID=$(echo ${SP_OUTPUT} | jq -r \'.tenant\')\nSP_PASSWORD=$(echo ${SP_OUTPUT} | jq -r \'.password\')\n\n# Store in Key Vault\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-client-id" \\\n  --value "${SP_CLIENT_ID}"\n\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-client-secret" \\\n  --value "${SP_PASSWORD}"\n\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-tenant-id" \\\n  --value "${SP_TENANT_ID}"\n\n# Step 4: Create Power BI Embedded Capacity\naz powerbi embedded-capacity create \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --sku "A1" \\\n  --location "${LOCATION}" \\\n  --administrator "${SP_OBJECT_ID}" \\\n  --tags ${TAGS}\n\n# Step 5: Create sample Power BI workspace collection\n# (Note: This requires Power BI API calls, storing configuration for reference)\ncat > /tmp/powerbi_config.json <<EOF\n{\n  "workspaceName": "SalesAnalytics",\n  "displayName": "Sales Analytics Workspace",\n  "description": "Embedded analytics workspace for customer reports",\n  "capacity": "${POWERBI_CAPACITY}",\n  "datasets": [\n    {\n      "name": "SalesData",\n      "description": "Historical sales data"\n    },\n    {\n      "name": "CustomerMetrics",\n      "description": "Customer metrics and KPIs"\n    }\n  ],\n  "reports": [\n    {\n      "name": "SalesOverview",\n      "description": "High-level sales dashboard"\n    },\n    {\n      "name": "RegionalAnalysis",\n      "description": "Regional sales breakdown"\n    }\n  ]\n}\nEOF\n\n# Step 6: Enable Power BI Embedded capacity\naz powerbi embedded-capacity update \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --sku "A1"\n\n# Step 7: Create sample application database (for demo)\ncat > /tmp/powerbi_app_config.json <<EOF\n{\n  "appName": "CustomerDashboard",\n  "embedApiUrl": "https://api.powerbi.com",\n  "datasetId": "dataset-id-placeholder",\n  "reportId": "report-id-placeholder",\n  "workspaceId": "workspace-id-placeholder",\n  "permissions": ["View", "Update", "Create"],\n  "features": [\n    "Embedding",\n    "Export to PDF",\n    "Refresh",\n    "Filters"\n  ]\n}\nEOF\n\n# Step 8: Store application configuration in Key Vault\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-app-config" \\\n  --value @/tmp/powerbi_app_config.json\n\n# Step 9: Create storage account for Power BI export scenarios\nSTORAGE_ACCOUNT="azmkrpbi${UNIQUE_ID}"\n\naz storage account create \\\n  --name "${STORAGE_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --sku Standard_LRS \\\n  --kind StorageV2 \\\n  --tags ${TAGS}\n\n# Step 10: Set CORS on storage for embedded reports\naz storage cors add \\\n  --services b \\\n  --methods GET POST PUT DELETE \\\n  --allowed-origins "*" \\\n  --allowed-headers "*" \\\n  --exposed-headers "*" \\\n  --account-name "${STORAGE_ACCOUNT}"\n\necho ""\necho "=========================================="\necho "Power BI Embedded Capacity Created"\necho "Capacity Name: ${POWERBI_CAPACITY}"\necho "Service Principal: ${APP_NAME}"\necho "Config stored in Key Vault: ${KEYVAULT}"\necho "=========================================="\n```\n\n### Validation\n```bash\n# Verify Resource Group\naz group show --name "${RESOURCE_GROUP}"\n\n# Verify Power BI Embedded Capacity\naz powerbi embedded-capacity show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}"\n\n# Check capacity status\naz powerbi embedded-capacity show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --query "state" -o tsv\n\n# Verify Key Vault\naz keyvault show --name "${KEYVAULT}"\n\n# List Key Vault secrets\naz keyvault secret list \\\n  --vault-name "${KEYVAULT}" \\\n  --query "[].name" -o table\n\n# List all resources\naz resource list --resource-group "${RESOURCE_GROUP}" --output table\n```\n\n---\n\n## Phase 2: Mid-Day Operations and Management\n\n### Management Operations\n```bash\n# Operation 1: Scale Power BI Embedded capacity\naz powerbi embedded-capacity update \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --sku "A2"\n\n# Operation 2: Check capacity SKU\naz powerbi embedded-capacity show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --query "sku" -o tsv\n\n# Operation 3: Suspend capacity (to save costs during off-hours)\naz powerbi embedded-capacity update \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${POWERBI_CAPACITY}" \\\n  --mode "Gen2"\n\n# Operation 4: Monitor capacity metrics\naz monitor metrics list \\\n  --resource "/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.PowerBIDedicated/capacities/${POWERBI_CAPACITY}" \\\n  --metric "CPU%" \\\n  --start-time $(date -u -d \'1 hour ago\' \'+%Y-%m-%dT%H:%M:%SZ\') \\\n  --end-time $(date -u \'+%Y-%m-%dT%H:%M:%SZ\')\n\n# Operation 5: Create additional Key Vault secret for workspace token\nWORKSPACE_TOKEN="token-placeholder-$(date +%s)"\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-workspace-token" \\\n  --value "${WORKSPACE_TOKEN}"\n\n# Operation 6: Retrieve configuration from Key Vault\naz keyvault secret show \\\n  --vault-name "${KEYVAULT}" \\\n  --name "powerbi-client-id" \\\n  --query "value" -o tsv\n\n# Operation 7: Create service principal assignment\naz ad app permission add \\\n  --id ${SP_CLIENT_ID} \\\n  --api 00000009-0000-0000-c000-000000000000 \\\n  --api-permissions "dcf25eaf-e99c-434c-a505-352a08913b1f=Application"\n\n# Operation 8: Upload sample Power BI report file (for reference)\ncat > /tmp/report_manifest.json <<EOF\n{\n  "reports": [\n    {\n      "id": "report-1",\n      "name": "Sales Dashboard",\n      "description": "Main sales metrics dashboard",\n      "refreshSchedule": "daily at 2 AM"\n    },\n    {\n      "id": "report-2",\n      "name": "Customer Analysis",\n      "description": "Deep dive customer metrics",\n      "refreshSchedule": "weekly on Monday"\n    }\n  ]\n}\nEOF\n\nSTORAGE_KEY=$(az storage account keys list \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --query \'[0].value\' -o tsv)\n\naz storage blob create-container \\\n  --name "powerbi-artifacts" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" 2>/dev/null || true\n\naz storage blob upload \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --container-name "powerbi-artifacts" \\\n  --name "report_manifest.json" \\\n  --file /tmp/report_manifest.json\n```\n\n---\n\n## Phase 3: Cleanup and Tear-Down\n\n### Cleanup Steps\n```bash\n# Step 1: Delete Service Principal\naz ad sp delete --id ${SP_OBJECT_ID}\n\n# Step 2: Delete application registration\naz ad app delete --id ${SP_CLIENT_ID}\n\n# Step 3: Delete the entire resource group\naz group delete \\\n  --name "${RESOURCE_GROUP}" \\\n  --yes \\\n  --no-wait\n\n# Step 4: Verify deletion\nsleep 120\naz group exists --name "${RESOURCE_GROUP}"\n\n# Step 5: Confirm cleanup\necho "Verifying cleanup..."\naz resource list --resource-group "${RESOURCE_GROUP}" 2>&1 | grep "could not be found" && echo "âœ“ Resource group successfully deleted"\n\n# Step 6: Clean up local files\nrm -rf /tmp/powerbi_config.json /tmp/powerbi_app_config.json /tmp/report_manifest.json\n```\n\n---\n\n## Resource Naming Convention\n- Resource Group: `azurehaymaker-analytics-powerbi-${UNIQUE_ID}-rg`\n- Power BI Embedded Capacity: `azurehaymaker-pbi-${UNIQUE_ID}`\n- Storage Account: `azmkrpbi${UNIQUE_ID}`\n- Key Vault: `azurehaymaker-kv-${UNIQUE_ID}`\n- Service Principal App: `azurehaymaker-powerbi-app-${UNIQUE_ID}`\n\nAll resources tagged with: `AzureHayMaker-managed=true`\n\n---\n\n## Documentation References\n- [Power BI Embedded Overview](https://learn.microsoft.com/en-us/azure/power-bi-embedded/overview)\n- [Capacity and SKUs](https://learn.microsoft.com/en-us/azure/power-bi-embedded/capacity-skus)\n- [Power BI Embedding for Customers](https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-sample-for-customers)\n- [Service Principal Authentication](https://learn.microsoft.com/en-us/power-bi/developer/embedded/embed-service-principal)\n- [Power BI REST API](https://learn.microsoft.com/en-us/rest/api/power-bi/)\n\n---\n\n## Automation Tool\n**Recommended**: Azure CLI\n\n**Rationale**: Azure CLI handles capacity provisioning and Key Vault management efficiently. Power BI API calls for workspace and report management are typically handled by application code or Power BI management tools.\n\n---\n\n## Estimated Duration\n- **Deployment**: 15-20 minutes\n- **Operations Phase**: 8 hours (with scaling, monitoring, and configuration)\n- **Cleanup**: 10-15 minutes\n\n---\n\n## Notes\n- Power BI Embedded supports multiple SKUs (A1-A3, Gen2)\n- Service Principal authentication enables programmatic access\n- Capacity must be paused/resumed to save costs\n- Tokens are time-limited and must be refreshed\n- All operations scoped to single tenant and subscription\n- Reports can be embedded in web applications and Power BI apps\n- Premium SKUs support dedicated capacity for predictable performance\n\n\n## Execution Plan\n\n### Phase 1: Planning\nPlan approach and strategy\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: planning, analysis\n\n### Phase 2: Implementation\nImplement solution\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: coding, configuration\n**Dependencies**: Planning\n\n### Phase 3: Testing\nTest implementation\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: testing, validation\n**Dependencies**: Implementation\n\n### Phase 4: Deployment\nDeploy solution\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: deployment, verification\n**Dependencies**: Testing\n\n## Success Criteria\n- Goal \'Scenario: Power BI Embedded Reports...\' is achieved\n\n## Instructions\nExecute the plan above autonomously:\n1. Follow each phase in sequence\n2. Use available skills and tools\n3. Verify success criteria are met\n4. Report progress and completion',
        "working_dir": ".",
        "sdk": "claude",
        "ui_mode": False,
        "success_criteria": ["Goal 'Scenario: Power BI Embedded Reports...' is achieved"],
        "constraints": [],
    }

    # Read initial prompt
    prompt_path = Path(__file__).parent / "prompt.md"
    if not prompt_path.exists():
        print("Error: prompt.md not found")
        sys.exit(1)

    initial_prompt = prompt_path.read_text()

    # Create auto-mode instance
    auto_mode = AutoMode(
        sdk=config.get("sdk", "claude"),
        prompt=initial_prompt,
        max_turns=config.get("max_turns", 10),
        working_dir=Path(__file__).parent,
        ui_mode=config.get("ui_mode", False),
    )

    # Run agent
    print("Starting reporting-scenario:-power-embedded-agent...")
    print("Goal: Scenario: Power BI Embedded Reports")
    print("Estimated duration: 2 hours 36 minutes")
    print()

    exit_code = auto_mode.run()

    if exit_code == 0:
        print("\nGoal achieved successfully!")
    else:
        print(f"\nGoal execution failed with code {exit_code}")

    return exit_code


if __name__ == "__main__":
    sys.exit(main())
