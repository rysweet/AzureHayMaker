{
  "bundle_id": "69c69155-4636-45dd-a2f8-1d2827bbd065",
  "name": "monitoring-scenario:-azure-machine-agent",
  "version": "1.0.0",
  "metadata": {
    "domain": "monitoring",
    "complexity": "simple",
    "phase_count": 4,
    "skill_count": 2,
    "estimated_duration": "22 minutes",
    "required_capabilities": [
      "instrumentation",
      "notification",
      "configuration",
      "alerting",
      "anomaly-detection",
      "analysis",
      "aggregation",
      "data-collection"
    ],
    "skill_names": [
      "monitor",
      "data-processor"
    ],
    "parallel_opportunities": 0,
    "risk_factors": [
      "Standard execution risks apply"
    ]
  },
  "auto_mode_config": {
    "max_turns": 6,
    "initial_prompt": "# Goal: Scenario: Azure Machine Learning Workspace Setup\n\n## Objective\n# Scenario: Azure Machine Learning Workspace Setup\n\n## Technology Area\nAI & ML\n\n## Company Profile\n- **Company Size**: Enterprise\n- **Industry**: Manufacturing / Predictive Analytics\n- **Use Case**: Set up ML workspace for training predictive models, managing experiments, and automating model deployment pipelines\n\n## Scenario Description\nCreate and configure Azure Machine Learning workspace with compute resources, storage, and managed identity. Set up ML experiments, register models, and establish CI/CD integration for automated model training and deployment.\n\n## Azure Services Used\n- Azure Machine Learning Service\n- Azure Storage Account (for data and models)\n- Azure Cosmos DB (for experiment metadata)\n- Azure Container Registry (for model containers)\n- Azure Key Vault (for credentials)\n- Azure Application Insights (for monitoring)\n\n## Prerequisites\n- Azure subscription with Contributor role\n- Azure CLI with ML extension installed (`az extension add -n ml`)\n- Python SDK for ML (optional but recommended)\n- Docker (optional for custom containers)\n\n---\n\n## Phase 1: Deployment and Validation\n\n### Environment Setup\n```bash\n# Set variables\nUNIQUE_ID=$(date +%Y%m%d%H%M%S)\nRESOURCE_GROUP=\"azurehaymaker-ml-${UNIQUE_ID}-rg\"\nLOCATION=\"eastus\"\nML_WORKSPACE=\"azurehaymaker-ml-${UNIQUE_ID}\"\nSTORAGE_ACCOUNT=\"azhmaklws${UNIQUE_ID}\"\nCONTAINER_REGISTRY=\"azhmaklcr${UNIQUE_ID}\"\nKEYVAULT=\"azurehaymaker-kv-${UNIQUE_ID}\"\nINSIGHTS_NAME=\"azurehaymaker-insights-${UNIQUE_ID}\"\nCOMPUTE_CLUSTER=\"ml-cluster-${UNIQUE_ID}\"\n\n# Tags\nTAGS=\"AzureHayMaker-managed=true Scenario=ai-ml-workspace Owner=AzureHayMaker\"\n```\n\n### Deployment Steps\n```bash\n# Step 1: Create Resource Group\naz group create \\\n  --name \"${RESOURCE_GROUP}\" \\\n  --location \"${LOCATION}\" \\\n  --tags ${TAGS}\n\n# Step 2: Create Storage Account for ML workspace\naz storage account create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --name \"${STORAGE_ACCOUNT}\" \\\n  --location \"${LOCATION}\" \\\n  --sku Standard_LRS \\\n  --kind StorageV2 \\\n  --tags ${TAGS}\n\n# Step 3: Create storage containers\nSTORAGE_KEY=$(az storage account keys list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --query '[0].value' -o tsv)\n\naz storage container create \\\n  --name \"training-data\" \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --account-key \"${STORAGE_KEY}\" \\\n  --public-access off\n\naz storage container create \\\n  --name \"models\" \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --account-key \"${STORAGE_KEY}\" \\\n  --public-access off\n\naz storage container create \\\n  --name \"outputs\" \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --account-key \"${STORAGE_KEY}\" \\\n  --public-access off\n\n# Step 4: Create Container Registry for model images\naz acr create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --name \"${CONTAINER_REGISTRY}\" \\\n  --sku Basic \\\n  --location \"${LOCATION}\" \\\n  --tags ${TAGS}\n\n# Step 5: Create Key Vault for credentials\naz keyvault create \\\n  --name \"${KEYVAULT}\" \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --location \"${LOCATION}\" \\\n  --tags ${TAGS}\n\n# Step 6: Create Application Insights\naz monitor app-insights component create \\\n  --app \"${INSIGHTS_NAME}\" \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --location \"${LOCATION}\" \\\n  --kind web \\\n  --tags ${TAGS}\n\n# Step 7: Get Application Insights instrumentation key\nINSIGHTS_KEY=$(az monitor app-insights component show \\\n  --app \"${INSIGHTS_NAME}\" \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --query \"instrumentationKey\" -o tsv)\n\n# Step 8: Create Machine Learning Workspace\naz ml workspace create \\\n  --file - <<EOF\n{\n  \"name\": \"${ML_WORKSPACE}\",\n  \"resource_group\": \"${RESOURCE_GROUP}\",\n  \"location\": \"${LOCATION}\",\n  \"display_name\": \"Azure HayMaker ML Workspace\",\n  \"description\": \"ML workspace for model training and deployment\",\n  \"storage_account\": \"/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.Storage/storageAccounts/${STORAGE_ACCOUNT}\",\n  \"key_vault\": \"/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.KeyVault/vaults/${KEYVAULT}\",\n  \"container_registry\": \"/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.ContainerRegistry/registries/${CONTAINER_REGISTRY}\",\n  \"application_insights\": \"/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.Insights/components/${INSIGHTS_NAME}\",\n  \"tags\": {\n    \"AzureHayMaker-managed\": \"true\",\n    \"Scenario\": \"ai-ml-workspace\"\n  }\n}\nEOF\n\n# Step 9: Create Compute Cluster for training\naz ml compute create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"${COMPUTE_CLUSTER}\" \\\n  --type \"AmlCompute\" \\\n  --min-instances 0 \\\n  --max-instances 4 \\\n  --size \"Standard_DS2_v2\" \\\n  --idle-time-before-scale-down 300\n\n# Step 10: Create compute instance for development\naz ml compute create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"dev-instance-${UNIQUE_ID}\" \\\n  --type \"ComputeInstance\" \\\n  --size \"Standard_D2s_v3\"\n```\n\n### Validation\n```bash\n# Verify Resource Group\naz group show --name \"${RESOURCE_GROUP}\"\n\n# Verify Storage Account\naz storage account show --name \"${STORAGE_ACCOUNT}\"\n\n# Verify Container Registry\naz acr show \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --name \"${CONTAINER_REGISTRY}\"\n\n# Verify Key Vault\naz keyvault show --name \"${KEYVAULT}\"\n\n# Verify Application Insights\naz monitor app-insights component show \\\n  --app \"${INSIGHTS_NAME}\" \\\n  --resource-group \"${RESOURCE_GROUP}\"\n\n# Verify ML Workspace\naz ml workspace show \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --name \"${ML_WORKSPACE}\"\n\n# List compute resources\naz ml compute list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --output table\n\n# List all resources\naz resource list --resource-group \"${RESOURCE_GROUP}\" --output table\n```\n\n---\n\n## Phase 2: Mid-Day Operations and Management\n\n### Management Operations\n```bash\n# Operation 1: Create and register training data\ncat > /tmp/training-data.csv << EOF\nfeature1,feature2,feature3,label\n1.5,2.3,3.1,0\n2.1,3.2,4.5,1\n1.2,2.0,3.5,0\n3.1,4.2,5.1,1\nEOF\n\nSTORAGE_KEY=$(az storage account keys list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --query '[0].value' -o tsv)\n\naz storage blob upload \\\n  --account-name \"${STORAGE_ACCOUNT}\" \\\n  --account-key \"${STORAGE_KEY}\" \\\n  --container-name \"training-data\" \\\n  --name \"training-data-${UNIQUE_ID}.csv\" \\\n  --file /tmp/training-data.csv\n\n# Operation 2: Create ML Dataset from storage\naz ml data create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --file - <<EOF\n{\n  \"name\": \"training-dataset-${UNIQUE_ID}\",\n  \"description\": \"Training data for model\",\n  \"path\": \"azureml://subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/datastores/workspaceblobstore/paths/training-data/training-data-${UNIQUE_ID}.csv\",\n  \"type\": \"mltable\"\n}\nEOF\n\n# Operation 3: List registered datasets\naz ml data list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --output table\n\n# Operation 4: Create experiment\naz ml experiment create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"exp-model-training-${UNIQUE_ID}\"\n\n# Operation 5: Get workspace details and configuration\naz ml workspace show \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --name \"${ML_WORKSPACE}\" \\\n  --query \"{Name: name, Location: location, StorageAccount: storage_account, ContainerRegistry: container_registry}\"\n\n# Operation 6: Check compute cluster status\naz ml compute show \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"${COMPUTE_CLUSTER}\" \\\n  --query \"{Name: name, Type: type, ProvisioningState: provisioning_state, RunningCount: current_node_count}\"\n\n# Operation 7: Monitor workspace metrics\naz monitor metrics list \\\n  --resource \"/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.MachineLearningServices/workspaces/${ML_WORKSPACE}\" \\\n  --metric \"cpuUsagePercentage\" \\\n  --start-time $(date -u -d '1 hour ago' '+%Y-%m-%dT%H:%M:%SZ') \\\n  --end-time $(date -u '+%Y-%m-%dT%H:%M:%SZ')\n\n# Operation 8: List models in workspace\naz ml model list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --output table\n\n# Operation 9: Create environment for training\naz ml environment create \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --file - <<EOF\n{\n  \"name\": \"sklearn-env-${UNIQUE_ID}\",\n  \"description\": \"Environment for scikit-learn training\",\n  \"conda_file\": {\n    \"name\": \"sklearn_env\",\n    \"channels\": [\"conda-forge\"],\n    \"dependencies\": [\n      \"python=3.11\",\n      \"pip\",\n      {\n        \"pip\": [\n          \"scikit-learn==1.3.0\",\n          \"pandas==2.0.0\",\n          \"numpy==1.24.0\"\n        ]\n      }\n    ]\n  }\n}\nEOF\n\n# Operation 10: List environments\naz ml environment list \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --output table\n\n# Operation 11: Scale compute cluster\naz ml compute update \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"${COMPUTE_CLUSTER}\" \\\n  --min-instances 0 \\\n  --max-instances 8\n\n# Operation 12: Get compute instance details\naz ml compute show \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"dev-instance-${UNIQUE_ID}\" \\\n  --query \"{Name: name, Type: type, State: state, ComputeType: compute_type}\"\n```\n\n---\n\n## Phase 3: Cleanup and Tear-Down\n\n### Cleanup Steps\n```bash\n# Step 1: Delete all compute instances\naz ml compute delete \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"${COMPUTE_CLUSTER}\" \\\n  --yes\n\naz ml compute delete \\\n  --resource-group \"${RESOURCE_GROUP}\" \\\n  --workspace-name \"${ML_WORKSPACE}\" \\\n  --name \"dev-instance-${UNIQUE_ID}\" \\\n  --yes\n\n# Step 2: Delete the entire resource group (includes all resources)\naz group delete \\\n  --name \"${RESOURCE_GROUP}\" \\\n  --yes \\\n  --no-wait\n\n# Step 3: Wait for deletion to complete\necho \"Waiting for resource group deletion...\"\nsleep 120\n\n# Step 4: Verify deletion\naz group exists --name \"${RESOURCE_GROUP}\"\n\n# Step 5: Confirm cleanup\necho \"Verifying cleanup...\"\naz resource list --resource-group \"${RESOURCE_GROUP}\" 2>&1 | grep \"could not be found\" && echo \"\u2713 Resource group successfully deleted\"\n```\n\n---\n\n## Resource Naming Convention\n- Resource Group: `azurehaymaker-ml-${UNIQUE_ID}-rg`\n- ML Workspace: `azurehaymaker-ml-${UNIQUE_ID}`\n- Storage Account: `azhmaklws${UNIQUE_ID}`\n- Container Registry: `azhmaklcr${UNIQUE_ID}`\n- Key Vault: `azurehaymaker-kv-${UNIQUE_ID}`\n- App Insights: `azurehaymaker-insights-${UNIQUE_ID}`\n- Compute Cluster: `ml-cluster-${UNIQUE_ID}`\n\nAll resources tagged with: `AzureHayMaker-managed=true`\n\n---\n\n## Documentation References\n- [Azure Machine Learning Documentation](https://learn.microsoft.com/en-us/azure/machine-learning/)\n- [Create ML Workspace](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace)\n- [Azure ML Compute Resources](https://learn.microsoft.com/en-us/azure/machine-learning/concept-compute-target)\n- [Training Jobs in Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-train-cli)\n- [Register and Deploy Models](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where)\n- [Azure ML CLI Reference](https://learn.microsoft.com/en-us/cli/azure/ml)\n\n---\n\n## Automation Tool\n**Recommended**: Azure CLI with ML extension\n\n**Rationale**: Azure CLI with the ML extension provides comprehensive workspace and compute management. It handles infrastructure provisioning, compute resource scaling, and experiment tracking in a unified command interface.\n\n---\n\n## Estimated Duration\n- **Deployment**: 20-30 minutes\n- **Operations Phase**: 8+ hours (with dataset creation, environment setup, compute scaling, and monitoring)\n- **Cleanup**: 10-15 minutes\n\n---\n\n## Notes\n- ML Workspace integrates storage, container registry, and Key Vault automatically\n- Compute clusters auto-scale based on job demand and idle time settings\n- Environments define reproducible training dependencies and Python packages\n- Datasets are versioned and registered for experiment reproducibility\n- All operations scoped to single tenant and subscription\n- Experiments track training runs, metrics, and model artifacts\n- Container Registry supports custom training and inference images\n\n\n## Execution Plan\n\n### Phase 1: Setup Monitors\nConfigure monitoring\n**Estimated Duration**: 5 minutes\n**Required Capabilities**: configuration, instrumentation\n\n### Phase 2: Data Collection\nCollect metrics and logs\n**Estimated Duration**: 5 minutes\n**Required Capabilities**: data-collection, aggregation\n**Dependencies**: Setup Monitors\n\n### Phase 3: Analysis\nAnalyze monitoring data\n**Estimated Duration**: 5 minutes\n**Required Capabilities**: analysis, anomaly-detection\n**Dependencies**: Data Collection\n\n### Phase 4: Alerting\nSet up alerts\n**Estimated Duration**: 5 minutes\n**Required Capabilities**: alerting, notification\n**Dependencies**: Analysis\n\n## Success Criteria\n- Goal 'Scenario: Azure Machine Learning Workspace Setup...' is achieved\n\n## Instructions\nExecute the plan above autonomously:\n1. Follow each phase in sequence\n2. Use available skills and tools\n3. Verify success criteria are met\n4. Report progress and completion",
    "working_dir": ".",
    "sdk": "claude",
    "ui_mode": false,
    "success_criteria": [
      "Goal 'Scenario: Azure Machine Learning Workspace Setup...' is achieved"
    ],
    "constraints": []
  }
}
