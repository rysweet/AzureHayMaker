#!/usr/bin/env python3
"""
testing-scenario:-azure-openai-agent - Autonomous Goal-Seeking Agent

Generated by Amplihack Goal Agent Generator
"""

import sys
from pathlib import Path

# Add parent directory to path for amplihack imports
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from amplihack.launcher.auto_mode import AutoMode
except ImportError:
    print("Error: amplihack package not found")
    print("Install with: pip install amplihack")
    sys.exit(1)


def main():
    """Execute the goal-seeking agent."""
    # Load configuration
    config = {
        "max_turns": 18,
        "initial_prompt": '# Goal: Scenario: Azure OpenAI Service Deployment\n\n## Objective\n# Scenario: Azure OpenAI Service Deployment\n\n## Technology Area\nAI & ML\n\n## Company Profile\n- **Company Size**: Mid-size enterprise\n- **Industry**: Software Development / Consulting\n- **Use Case**: Deploy Azure OpenAI models for code generation, content creation, and AI-powered application features\n\n## Scenario Description\nDeploy Azure OpenAI Service with GPT model access, configure API endpoints, and demonstrate model inference operations. This scenario covers resource provisioning, model deployment, API testing, and operational management.\n\n## Azure Services Used\n- Azure OpenAI Service\n- Azure Storage Account (for prompt/response logs)\n- Azure Key Vault (for API credentials and model keys)\n- Azure Application Insights (for monitoring)\n\n## Prerequisites\n- Azure subscription with Contributor role\n- Azure CLI installed and configured\n- Azure OpenAI API access (requires registration)\n- cURL or similar tool for API calls\n\n---\n\n## Phase 1: Deployment and Validation\n\n### Environment Setup\n```bash\n# Set variables\nUNIQUE_ID=$(date +%Y%m%d%H%M%S)\nRESOURCE_GROUP="azurehaymaker-openai-${UNIQUE_ID}-rg"\nLOCATION="eastus"\nOPENAI_RESOURCE="azurehaymaker-openai-${UNIQUE_ID}"\nSTORAGE_ACCOUNT="azurehaymaker${UNIQUE_ID}"\nKEYVAULT="azurehaymaker-kv-${UNIQUE_ID}"\nINSIGHTS_NAME="azurehaymaker-insights-${UNIQUE_ID}"\nDEPLOYMENT_NAME="gpt-35-turbo-deployment"\n\n# Tags\nTAGS="AzureHayMaker-managed=true Scenario=ai-ml-openai Owner=AzureHayMaker"\n```\n\n### Deployment Steps\n```bash\n# Step 1: Create Resource Group\naz group create \\\n  --name "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 2: Create Azure OpenAI Service\naz cognitiveservices account create \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${OPENAI_RESOURCE}" \\\n  --kind OpenAI \\\n  --sku s0 \\\n  --location "${LOCATION}" \\\n  --custom-domain "${OPENAI_RESOURCE}" \\\n  --tags ${TAGS}\n\n# Step 3: Get OpenAI endpoint and key\nOPENAI_ENDPOINT=$(az cognitiveservices account show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${OPENAI_RESOURCE}" \\\n  --query "properties.endpoint" -o tsv)\n\nOPENAI_KEY=$(az cognitiveservices account keys list \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${OPENAI_RESOURCE}" \\\n  --query "key1" -o tsv)\n\necho "OpenAI Endpoint: ${OPENAI_ENDPOINT}"\necho "OpenAI Key: ${OPENAI_KEY}"\n\n# Step 4: Create model deployment using Azure CLI (if supported)\n# Note: Model deployments may require Azure Portal or ARM templates\n# This creates the deployment configuration\ncat > /tmp/deployment-config.json << EOF\n{\n  "sku": {\n    "name": "standard",\n    "capacity": 1\n  },\n  "properties": {\n    "model": {\n      "format": "OpenAI",\n      "name": "gpt-35-turbo",\n      "version": "0613"\n    },\n    "scaleSettings": {\n      "scaleType": "manual",\n      "capacity": 1\n    }\n  }\n}\nEOF\n\n# Step 5: Create Storage Account for logs\naz storage account create \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${STORAGE_ACCOUNT}" \\\n  --location "${LOCATION}" \\\n  --sku Standard_LRS \\\n  --kind StorageV2 \\\n  --tags ${TAGS}\n\n# Step 6: Create storage containers\nSTORAGE_KEY=$(az storage account keys list \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --query \'[0].value\' -o tsv)\n\naz storage container create \\\n  --name "prompts" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --public-access off\n\naz storage container create \\\n  --name "responses" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --public-access off\n\naz storage container create \\\n  --name "logs" \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --public-access off\n\n# Step 7: Create Key Vault for credentials\naz keyvault create \\\n  --name "${KEYVAULT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 8: Store OpenAI credentials in Key Vault\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "openai-endpoint" \\\n  --value "${OPENAI_ENDPOINT}"\n\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "openai-key" \\\n  --value "${OPENAI_KEY}"\n\n# Step 9: Create Application Insights for monitoring\naz monitor app-insights component create \\\n  --app "${INSIGHTS_NAME}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --kind web \\\n  --tags ${TAGS}\n\n# Step 10: Get Application Insights key\nINSIGHTS_KEY=$(az monitor app-insights component show \\\n  --app "${INSIGHTS_NAME}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --query "instrumentationKey" -o tsv)\n\necho "Application Insights Key: ${INSIGHTS_KEY}"\n```\n\n### Validation\n```bash\n# Verify Resource Group\naz group show --name "${RESOURCE_GROUP}"\n\n# Verify OpenAI Resource\naz cognitiveservices account show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${OPENAI_RESOURCE}"\n\n# Verify Storage Account\naz storage account show --name "${STORAGE_ACCOUNT}"\n\n# Verify Storage Containers\naz storage container list \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --output table\n\n# Verify Key Vault\naz keyvault show --name "${KEYVAULT}"\n\n# Verify Application Insights\naz monitor app-insights component show \\\n  --app "${INSIGHTS_NAME}" \\\n  --resource-group "${RESOURCE_GROUP}"\n\n# List all resources\naz resource list --resource-group "${RESOURCE_GROUP}" --output table\n\n# Test OpenAI API connectivity\ncurl -I -X GET "${OPENAI_ENDPOINT}openai/models" \\\n  -H "api-key: ${OPENAI_KEY}"\n```\n\n---\n\n## Phase 2: Mid-Day Operations and Management\n\n### Management Operations\n```bash\n# Operation 1: Test chat completion API with GPT-3.5\ncurl -X POST "${OPENAI_ENDPOINT}openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-15-preview" \\\n  -H "api-key: ${OPENAI_KEY}" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      {"role": "system", "content": "You are a helpful assistant."},\n      {"role": "user", "content": "What is Azure OpenAI Service?"}\n    ],\n    "temperature": 0.7,\n    "max_tokens": 256\n  }\' | jq \'.\' > /tmp/openai-response-1.json\n\ncat /tmp/openai-response-1.json\n\n# Operation 2: Test code generation capability\ncurl -X POST "${OPENAI_ENDPOINT}openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-15-preview" \\\n  -H "api-key: ${OPENAI_KEY}" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      {"role": "user", "content": "Write a Python function to calculate factorial"}\n    ],\n    "temperature": 0.5,\n    "max_tokens": 512\n  }\' | jq \'.choices[0].message.content\'\n\n# Operation 3: Store prompt in storage\ncat > /tmp/prompt-log.txt << EOF\nPrompt: What is Azure OpenAI Service?\nTimestamp: $(date -u \'+%Y-%m-%dT%H:%M:%SZ\')\nModel: gpt-35-turbo\nEOF\n\naz storage blob upload \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --container-name "prompts" \\\n  --name "prompt-001-$(date +%s).txt" \\\n  --file /tmp/prompt-log.txt\n\n# Operation 4: Store response in storage\naz storage blob upload \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --container-name "responses" \\\n  --name "response-001-$(date +%s).json" \\\n  --file /tmp/openai-response-1.json\n\n# Operation 5: Get OpenAI resource metrics\naz monitor metrics list \\\n  --resource "/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.CognitiveServices/accounts/${OPENAI_RESOURCE}" \\\n  --metric "SuccessfulRequests" \\\n  --start-time $(date -u -d \'1 hour ago\' \'+%Y-%m-%dT%H:%M:%SZ\') \\\n  --end-time $(date -u \'+%Y-%m-%dT%H:%M:%SZ\')\n\n# Operation 6: Test with different temperature (more creative)\ncurl -X POST "${OPENAI_ENDPOINT}openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-15-preview" \\\n  -H "api-key: ${OPENAI_KEY}" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      {"role": "user", "content": "Create a creative product name for a new AI tool"}\n    ],\n    "temperature": 0.9,\n    "max_tokens": 100\n  }\' | jq \'.choices[0].message.content\'\n\n# Operation 7: Test with system role and context\ncurl -X POST "${OPENAI_ENDPOINT}openai/deployments/gpt-35-turbo/chat/completions?api-version=2024-02-15-preview" \\\n  -H "api-key: ${OPENAI_KEY}" \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      {"role": "system", "content": "You are a technical documentation expert. Answer in bullet points."},\n      {"role": "user", "content": "Explain the benefits of using Azure OpenAI Service"}\n    ],\n    "temperature": 0.3,\n    "max_tokens": 256\n  }\' | jq \'.choices[0].message.content\'\n\n# Operation 8: List all prompts stored\naz storage blob list \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --container-name "prompts" \\\n  --output table\n\n# Operation 9: List all responses stored\naz storage blob list \\\n  --account-name "${STORAGE_ACCOUNT}" \\\n  --account-key "${STORAGE_KEY}" \\\n  --container-name "responses" \\\n  --output table\n\n# Operation 10: Check OpenAI account status and quota\naz cognitiveservices account show \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${OPENAI_RESOURCE}" \\\n  --query "{Name: name, Kind: kind, Sku: sku.name, Endpoint: properties.endpoint, ProvisioningState: properties.provisioningState}"\n\n# Operation 11: Retrieve stored credentials\naz keyvault secret list --vault-name "${KEYVAULT}" --output table\n\n# Operation 12: Monitor Application Insights\naz monitor app-insights metrics show \\\n  --app "${INSIGHTS_NAME}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --metric "requests/rate"\n```\n\n---\n\n## Phase 3: Cleanup and Tear-Down\n\n### Cleanup Steps\n```bash\n# Step 1: Delete the entire resource group (includes all resources)\naz group delete \\\n  --name "${RESOURCE_GROUP}" \\\n  --yes \\\n  --no-wait\n\n# Step 2: Wait for deletion to complete\necho "Waiting for resource group deletion..."\nsleep 120\n\n# Step 3: Verify deletion\naz group exists --name "${RESOURCE_GROUP}"\n\n# Step 4: Confirm cleanup\necho "Verifying cleanup..."\naz resource list --resource-group "${RESOURCE_GROUP}" 2>&1 | grep "could not be found" && echo "âœ“ Resource group successfully deleted"\n```\n\n---\n\n## Resource Naming Convention\n- Resource Group: `azurehaymaker-openai-${UNIQUE_ID}-rg`\n- OpenAI Service: `azurehaymaker-openai-${UNIQUE_ID}`\n- Storage Account: `azurehaymaker${UNIQUE_ID}`\n- Key Vault: `azurehaymaker-kv-${UNIQUE_ID}`\n- App Insights: `azurehaymaker-insights-${UNIQUE_ID}`\n\nAll resources tagged with: `AzureHayMaker-managed=true`\n\n---\n\n## Documentation References\n- [Azure OpenAI Service Documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/)\n- [Azure OpenAI API Reference](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference)\n- [Chat Completions API Guide](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/chatgpt?tabs=python)\n- [Deploy Azure OpenAI Models](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource)\n- [Azure OpenAI Quotas and Limits](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quotas-limits)\n- [Best Practices for Azure OpenAI](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/best-practices)\n\n---\n\n## Automation Tool\n**Recommended**: Azure CLI with REST API\n\n**Rationale**: Azure CLI handles infrastructure provisioning, while REST API calls via curl provide direct access to OpenAI chat completion and code generation APIs. This combination enables comprehensive testing and operational management.\n\n---\n\n## Estimated Duration\n- **Deployment**: 15-20 minutes\n- **Operations Phase**: 8+ hours (with multiple model testing, prompt iterations, and monitoring)\n- **Cleanup**: 5-10 minutes\n\n---\n\n## Notes\n- Azure OpenAI Service requires prior registration and access approval\n- Model deployments need to be created via Azure Portal, REST API, or ARM templates\n- Chat Completions API supports system roles, user messages, and assistant responses\n- Temperature parameter (0-2) controls response randomness and creativity\n- Max tokens parameter limits response length\n- All operations scoped to single tenant and subscription\n- Credentials securely stored in Key Vault\n- Prompts and responses logged to storage for audit and analysis\n\n\n## Execution Plan\n\n### Phase 1: Test Planning\nPlan test strategy\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-design, planning\n\n### Phase 2: Test Implementation\nImplement test cases\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-coding, framework-setup\n**Dependencies**: Test Planning\n\n### Phase 3: Test Execution\nRun test suite\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-execution, automation\n**Dependencies**: Test Implementation\n\n### Phase 4: Results Analysis\nAnalyze test results\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: analysis, reporting\n**Dependencies**: Test Execution\n\n## Success Criteria\n- Goal \'Scenario: Azure OpenAI Service Deployment...\' is achieved\n\n## Instructions\nExecute the plan above autonomously:\n1. Follow each phase in sequence\n2. Use available skills and tools\n3. Verify success criteria are met\n4. Report progress and completion',
        "working_dir": ".",
        "sdk": "claude",
        "ui_mode": False,
        "success_criteria": ["Goal 'Scenario: Azure OpenAI Service Deployment...' is achieved"],
        "constraints": [],
    }

    # Read initial prompt
    prompt_path = Path(__file__).parent / "prompt.md"
    if not prompt_path.exists():
        print("Error: prompt.md not found")
        sys.exit(1)

    initial_prompt = prompt_path.read_text()

    # Create auto-mode instance
    auto_mode = AutoMode(
        sdk=config.get("sdk", "claude"),
        prompt=initial_prompt,
        max_turns=config.get("max_turns", 10),
        working_dir=Path(__file__).parent,
        ui_mode=config.get("ui_mode", False),
    )

    # Run agent
    print("Starting testing-scenario:-azure-openai-agent...")
    print("Goal: Scenario: Azure OpenAI Service Deployment")
    print("Estimated duration: 2 hours 36 minutes")
    print()

    exit_code = auto_mode.run()

    if exit_code == 0:
        print("\nGoal achieved successfully!")
    else:
        print(f"\nGoal execution failed with code {exit_code}")

    return exit_code


if __name__ == "__main__":
    sys.exit(main())
