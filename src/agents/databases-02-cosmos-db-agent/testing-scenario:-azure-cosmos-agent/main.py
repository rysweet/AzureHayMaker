#!/usr/bin/env python3
"""
testing-scenario:-azure-cosmos-agent - Autonomous Goal-Seeking Agent

Generated by Amplihack Goal Agent Generator
"""

import sys
from pathlib import Path

# Add parent directory to path for amplihack imports
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from amplihack.launcher.auto_mode import AutoMode
except ImportError:
    print("Error: amplihack package not found")
    print("Install with: pip install amplihack")
    sys.exit(1)


def main():
    """Execute the goal-seeking agent."""
    # Load configuration
    config = {
        "max_turns": 18,
        "initial_prompt": '# Goal: Scenario: Azure Cosmos DB with SQL API\n\n## Objective\n# Scenario: Azure Cosmos DB with SQL API\n\n## Technology Area\nDatabases\n\n## Company Profile\n- **Company Size**: Large enterprise\n- **Industry**: Retail / E-commerce\n- **Use Case**: Global-scale NoSQL database for customer profiles and product catalogs\n\n## Scenario Description\nDeploy Azure Cosmos DB with SQL API for globally distributed, low-latency access to document data. Configure containers, implement partitioning strategy, set up throughput scaling, and demonstrate backup capabilities.\n\n## Azure Services Used\n- Azure Cosmos DB (multi-model database)\n- Azure Key Vault (connection strings)\n- Azure Monitor (logging and monitoring)\n- Azure Backup (disaster recovery)\n\n## Prerequisites\n- Azure subscription with Contributor role\n- Azure CLI installed\n- A unique identifier for this scenario run\n\n---\n\n## Phase 1: Deployment and Validation\n\n### Environment Setup\n```bash\n# Set variables\nUNIQUE_ID=$(date +%Y%m%d%H%M%S)\nRESOURCE_GROUP="azurehaymaker-db-cosmos-${UNIQUE_ID}-rg"\nLOCATION="eastus"\nCOSMOS_ACCOUNT="azurehaymaker-cosmos-${UNIQUE_ID}"\nCOSMOS_DB="retaildb"\nKEYVAULT="azurehaymaker-kv-${UNIQUE_ID}"\nLOG_ANALYTICS="azurehaymaker-logs-${UNIQUE_ID}"\n\n# Tags\nTAGS="AzureHayMaker-managed=true Scenario=databases-cosmos-db Owner=AzureHayMaker"\n```\n\n### Deployment Steps\n```bash\n# Step 1: Create Resource Group\naz group create \\\n  --name "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 2: Create Key Vault\naz keyvault create \\\n  --name "${KEYVAULT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 3: Create Log Analytics Workspace\naz monitor log-analytics workspace create \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --workspace-name "${LOG_ANALYTICS}" \\\n  --location "${LOCATION}" \\\n  --tags ${TAGS}\n\n# Step 4: Create Cosmos DB Account\naz cosmosdb create \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --locations regionName="${LOCATION}" failoverPriority=0 \\\n  --default-consistency-level "Session" \\\n  --enable-multiple-write-locations true \\\n  --capabilities EnableServerless \\\n  --tags ${TAGS}\n\n# Step 5: Create database\naz cosmosdb sql database create \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${COSMOS_DB}" \\\n  --throughput 400\n\n# Step 6: Create containers with partition keys\naz cosmosdb sql container create \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Customers" \\\n  --partition-key-path "/customerId" \\\n  --throughput 400\n\naz cosmosdb sql container create \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Products" \\\n  --partition-key-path "/categoryId" \\\n  --throughput 400\n\naz cosmosdb sql container create \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Orders" \\\n  --partition-key-path "/customerId" \\\n  --throughput 400\n\n# Step 7: Enable automatic failover\naz cosmosdb failover-priority-change \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --failover-policies regionName="${LOCATION}" failoverPriority=0\n\n# Step 8: Get connection string\nCOSMOS_CONNECTION_STRING=$(az cosmosdb keys list \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --type "connection-strings" \\\n  --query "connectionStrings[0].connectionString" -o tsv)\n\n# Store in Key Vault\naz keyvault secret set \\\n  --vault-name "${KEYVAULT}" \\\n  --name "cosmos-connection-string" \\\n  --value "${COSMOS_CONNECTION_STRING}"\n\n# Step 9: Enable backup retention\naz cosmosdb update \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --backup-policy-type Periodic \\\n  --backup-interval 240 \\\n  --backup-retention 720\n\n# Step 10: Create diagnostic settings for monitoring\naz monitor diagnostic-settings create \\\n  --name "cosmos-diagnostics" \\\n  --resource "/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.DocumentDB/databaseAccounts/${COSMOS_ACCOUNT}" \\\n  --workspace "${LOG_ANALYTICS}" \\\n  --logs \'[{"category":"DataPlaneRequests","enabled":true}]\' \\\n  --metrics \'[{"category":"Requests","enabled":true}]\'\n\necho ""\necho "=========================================="\necho "Cosmos DB Account Created: ${COSMOS_ACCOUNT}"\necho "Database: ${COSMOS_DB}"\necho "Containers: Customers, Products, Orders"\necho "=========================================="\n```\n\n### Validation\n```bash\n# Verify Resource Group\naz group show --name "${RESOURCE_GROUP}"\n\n# Verify Cosmos DB Account\naz cosmosdb show \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}"\n\n# Check account status\naz cosmosdb show \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --query "provisioningState" -o tsv\n\n# List databases\naz cosmosdb sql database list \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --output table\n\n# List containers\naz cosmosdb sql container list \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --output table\n\n# Get container details\naz cosmosdb sql container show \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Customers"\n\n# Check throughput settings\naz cosmosdb sql container throughput show \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Customers"\n\n# List all resources\naz resource list --resource-group "${RESOURCE_GROUP}" --output table\n```\n\n---\n\n## Phase 2: Mid-Day Operations and Management\n\n### Management Operations\n```bash\n# Operation 1: Scale throughput for Customers container\naz cosmosdb sql container throughput update \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Customers" \\\n  --throughput 800\n\n# Operation 2: Add sample documents\n# Create sample customer data\ncat > /tmp/customer_sample.json <<EOF\n{\n  "customerId": "CUST001",\n  "name": "John Doe",\n  "email": "john@example.com",\n  "tier": "premium",\n  "registeredDate": "2024-01-01"\n}\nEOF\n\n# Operation 3: View container metrics\naz monitor metrics list \\\n  --resource "/subscriptions/$(az account show --query id -o tsv)/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.DocumentDB/databaseAccounts/${COSMOS_ACCOUNT}" \\\n  --metric "TotalRequests" \\\n  --start-time $(date -u -d \'1 hour ago\' \'+%Y-%m-%dT%H:%M:%SZ\') \\\n  --end-time $(date -u \'+%Y-%m-%dT%H:%M:%SZ\')\n\n# Operation 4: List backup information\naz cosmosdb backup show \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}"\n\n# Operation 5: Create point-in-time restore (for testing)\necho "To create a point-in-time restore:"\necho "az cosmosdb restore --account-name ${COSMOS_ACCOUNT} --resource-group ${RESOURCE_GROUP} --restore-timestamp $(date -u \'+%Y-%m-%dT%H:%M:%SZ\')"\n\n# Operation 6: Enable analytical store on Products container\naz cosmosdb sql container update \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Products" \\\n  --analytical-storage-ttl 86400\n\n# Operation 7: Monitor request usage\naz cosmosdb sql database show \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${COSMOS_DB}" \\\n  --query "properties.throughput" -o tsv\n\n# Operation 8: Create index policy for Customers\ncat > /tmp/index_policy.json <<EOF\n{\n  "indexingMode": "consistent",\n  "automatic": true,\n  "includedPaths": [\n    {\n      "path": "/*"\n    }\n  ],\n  "excludedPaths": [\n    {\n      "path": "/sensitive/*"\n    }\n  ]\n}\nEOF\n\n# Operation 9: Check connection limits\naz cosmosdb account show \\\n  --name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --query "virtualNetworkRules" -o table\n\n# Operation 10: List all containers with TTL settings\naz cosmosdb sql container list \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --query "[].{Name:name, PartitionKey:partitionKey.paths[0]}" -o table\n```\n\n---\n\n## Phase 3: Cleanup and Tear-Down\n\n### Cleanup Steps\n```bash\n# Step 1: Delete containers\naz cosmosdb sql container delete \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Customers" \\\n  --yes\n\naz cosmosdb sql container delete \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Products" \\\n  --yes\n\naz cosmosdb sql container delete \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --database-name "${COSMOS_DB}" \\\n  --name "Orders" \\\n  --yes\n\n# Step 2: Delete database\naz cosmosdb sql database delete \\\n  --account-name "${COSMOS_ACCOUNT}" \\\n  --resource-group "${RESOURCE_GROUP}" \\\n  --name "${COSMOS_DB}" \\\n  --yes\n\n# Step 3: Delete the entire resource group\naz group delete \\\n  --name "${RESOURCE_GROUP}" \\\n  --yes \\\n  --no-wait\n\n# Step 4: Verify deletion\nsleep 120\naz group exists --name "${RESOURCE_GROUP}"\n\n# Step 5: Confirm cleanup\necho "Verifying cleanup..."\naz resource list --resource-group "${RESOURCE_GROUP}" 2>&1 | grep "could not be found" && echo "âœ“ Resource group successfully deleted"\n\n# Step 6: Clean up local files\nrm -rf /tmp/customer_sample.json /tmp/index_policy.json\n```\n\n---\n\n## Resource Naming Convention\n- Resource Group: `azurehaymaker-db-cosmos-${UNIQUE_ID}-rg`\n- Cosmos DB Account: `azurehaymaker-cosmos-${UNIQUE_ID}`\n- Database: `retaildb`\n- Containers: `Customers`, `Products`, `Orders`\n- Key Vault: `azurehaymaker-kv-${UNIQUE_ID}`\n\nAll resources tagged with: `AzureHayMaker-managed=true`\n\n---\n\n## Documentation References\n- [Azure Cosmos DB Overview](https://learn.microsoft.com/en-us/azure/cosmos-db/introduction)\n- [SQL API for Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/sql/)\n- [Partitioning in Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/partitioning-overview)\n- [Throughput and RU/s](https://learn.microsoft.com/en-us/azure/cosmos-db/request-units)\n- [Cosmos DB CLI Reference](https://learn.microsoft.com/en-us/cli/azure/cosmosdb)\n\n---\n\n## Automation Tool\n**Recommended**: Azure CLI\n\n**Rationale**: Azure CLI provides excellent support for Cosmos DB operations including database, container, and throughput management. Simple and declarative for this scenario.\n\n---\n\n## Estimated Duration\n- **Deployment**: 15-20 minutes\n- **Operations Phase**: 8 hours (with scaling and monitoring)\n- **Cleanup**: 10-15 minutes\n\n---\n\n## Notes\n- Serverless billing option available for unpredictable workloads\n- Multiple write regions provide high availability\n- Session consistency balances consistency and performance\n- Automatic failover ensures business continuity\n- All operations scoped to single tenant and subscription\n- Point-in-time restore enables disaster recovery\n- TTL on documents enables automatic data cleanup\n\n\n## Execution Plan\n\n### Phase 1: Test Planning\nPlan test strategy\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-design, planning\n\n### Phase 2: Test Implementation\nImplement test cases\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-coding, framework-setup\n**Dependencies**: Test Planning\n\n### Phase 3: Test Execution\nRun test suite\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: test-execution, automation\n**Dependencies**: Test Implementation\n\n### Phase 4: Results Analysis\nAnalyze test results\n**Estimated Duration**: 30 minutes\n**Required Capabilities**: analysis, reporting\n**Dependencies**: Test Execution\n\n## Success Criteria\n- Goal \'Scenario: Azure Cosmos DB with SQL API...\' is achieved\n\n## Instructions\nExecute the plan above autonomously:\n1. Follow each phase in sequence\n2. Use available skills and tools\n3. Verify success criteria are met\n4. Report progress and completion',
        "working_dir": ".",
        "sdk": "claude",
        "ui_mode": False,
        "success_criteria": ["Goal 'Scenario: Azure Cosmos DB with SQL API...' is achieved"],
        "constraints": [],
    }

    # Read initial prompt
    prompt_path = Path(__file__).parent / "prompt.md"
    if not prompt_path.exists():
        print("Error: prompt.md not found")
        sys.exit(1)

    initial_prompt = prompt_path.read_text()

    # Create auto-mode instance
    auto_mode = AutoMode(
        sdk=config.get("sdk", "claude"),
        prompt=initial_prompt,
        max_turns=config.get("max_turns", 10),
        working_dir=Path(__file__).parent,
        ui_mode=config.get("ui_mode", False),
    )

    # Run agent
    print("Starting testing-scenario:-azure-cosmos-agent...")
    print("Goal: Scenario: Azure Cosmos DB with SQL API")
    print("Estimated duration: 2 hours 36 minutes")
    print()

    exit_code = auto_mode.run()

    if exit_code == 0:
        print("\nGoal achieved successfully!")
    else:
        print(f"\nGoal execution failed with code {exit_code}")

    return exit_code


if __name__ == "__main__":
    sys.exit(main())
